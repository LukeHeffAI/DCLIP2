{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating descriptors from descriptors_cub_gpt4_8_descriptors...\n",
      "Example description for class 'Black-footed Albatross': \"Black-footed Albatross, which has Seabird with contrasting black and white plumage\"\n",
      "\n",
      "Creating descriptor frequencies...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from load import *\n",
    "import os\n",
    "\n",
    "def save_to_json(similarity, json_output_path):\n",
    "    # Check if the file already exists\n",
    "    if os.path.exists(json_output_path):\n",
    "        with open(json_output_path, 'r') as f:\n",
    "            existing_data = json.load(f)\n",
    "    else:\n",
    "        existing_data = {}\n",
    "\n",
    "    # Update existing data with new similarity results\n",
    "    existing_data.update(similarity)\n",
    "\n",
    "    # Write the updated data back to the JSON file\n",
    "    with open(json_output_path, 'w') as f:\n",
    "        json.dump(existing_data, f, indent=4)\n",
    "\n",
    "def compute_class_description_cosine_similarity(data):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    data: dictionary containing class descriptions\n",
    "    \n",
    "    Compute the cosine similarity between each class and all images,\n",
    "    normalize these values, and save the results in JSON format.\n",
    "    \"\"\"\n",
    "    device = torch.device(hparams['device'])\n",
    "    model, preprocess = clip.load(hparams['model_size'], device=device, jit=False)\n",
    "    model.eval()\n",
    "\n",
    "    class_list = compute_class_list(data, sort_config=True)\n",
    "\n",
    "    class_descriptor_dict = load_json(hparams['descriptor_fname'])\n",
    "    class_list = compute_class_list(class_descriptor_dict, sort_config=True)\n",
    "    descriptor_list = compute_descriptor_list(class_descriptor_dict, sort_config=True)\n",
    "\n",
    "    class_list = [c.replace('-', ' ') for c in class_list]\n",
    "\n",
    "    seed_everything(hparams['seed'])\n",
    "\n",
    "    # Load the model and preprocessing\n",
    "    print(\"Loading model...\")\n",
    "    device = torch.device(hparams['device'])\n",
    "    model, preprocess = clip.load(hparams['model_size'], device=device, jit=False)\n",
    "    model.eval()\n",
    "    model.requires_grad_(False)\n",
    "\n",
    "    # Encode descriptions and labels\n",
    "    print(\"Encoding descriptions...\")\n",
    "    description_encodings = F.normalize(model.encode_text(clip.tokenize(descriptor_list).to(device)))\n",
    "    label_encodings = F.normalize(model.encode_text(clip.tokenize(class_list).to(device)))\n",
    "\n",
    "    cosine_similarity = torch.mm(description_encodings, label_encodings.T)\n",
    "    print(cosine_similarity.size())\n",
    "\n",
    "    cosine_similarity_per_class = cosine_similarity.cpu().detach().numpy()\n",
    "    print(\"cosine_similarity:\", cosine_similarity_per_class)\n",
    "\n",
    "    # Calculate average cosine similarity for each class\n",
    "    average_cosine_similarity = cosine_similarity.mean(dim=0).tolist()\n",
    "\n",
    "    similarity = {}\n",
    "    similarity[hparams['dataset']] = {}\n",
    "    for i, class_name in enumerate(class_list):\n",
    "        similarity[hparams['dataset']][class_name] = {}\n",
    "        similarity[hparams['dataset']][class_name][\"cos_sim\"] = cosine_similarity_per_class[i].tolist()\n",
    "        if len(similarity[hparams['dataset']][class_name][\"cos_sim\"]) == len(dataset_classes):\n",
    "            similarity[hparams['dataset']][class_name][\"cos_sim_sorted\"] = sorted(similarity[hparams['dataset']][class_name][\"cos_sim\"], reverse=True)\n",
    "            similarity[hparams['dataset']][class_name][\"average_cos_sim\"] = average_cosine_similarity[i]\n",
    "\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./descriptors/descriptors_cub_gpt4_8_descriptors\n",
      "Loading model...\n",
      "Encoding descriptions...\n",
      "torch.Size([1561, 200])\n",
      "cosine_similarity: [[0.6025 0.6504 0.541  ... 0.648  0.5273 0.578 ]\n",
      " [0.6167 0.689  0.551  ... 0.6553 0.535  0.587 ]\n",
      " [0.5977 0.6987 0.555  ... 0.699  0.6143 0.6064]\n",
      " ...\n",
      " [0.5723 0.6284 0.4668 ... 0.574  0.4639 0.5317]\n",
      " [0.59   0.6562 0.4878 ... 0.633  0.4963 0.5522]\n",
      " [0.5923 0.6777 0.4985 ... 0.6377 0.5063 0.562 ]]\n",
      "cub\n"
     ]
    }
   ],
   "source": [
    "descriptor_file_path = hparams['descriptor_fname']\n",
    "print(descriptor_file_path)\n",
    "\n",
    "class_descriptor_dict = load_json(descriptor_file_path)\n",
    "analysis_dict = compute_class_description_cosine_similarity(class_descriptor_dict)\n",
    "\n",
    "output_path_name = descriptor_file_path.split(\"/\")[-1].split(\".\")[0].split(\"_\")[1]\n",
    "print(output_path_name)\n",
    "json_file_path = f'class_analysis/class_analysis_{output_path_name}.json'\n",
    "\n",
    "save_to_json(analysis_dict, json_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise differences in all datasets from a particular dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'American-Three-toed Woodpecker'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 77\u001b[0m\n\u001b[1;32m     74\u001b[0m descriptor_dict \u001b[38;5;241m=\u001b[39m load_json(descriptor_file_path)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Generate and save the combined heatmap\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m \u001b[43mgenerate_combined_heatmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescriptor_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 35\u001b[0m, in \u001b[0;36mgenerate_combined_heatmap\u001b[0;34m(data, dataset_name, output_dir, descriptor_dict)\u001b[0m\n\u001b[1;32m     32\u001b[0m descriptor_list \u001b[38;5;241m=\u001b[39m compute_descriptor_list(descriptor_dict, sort_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Extract cosine similarity values for each class\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m similarities_per_class \u001b[38;5;241m=\u001b[39m [\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclass_name\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcos_sim\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m class_name \u001b[38;5;129;01min\u001b[39;00m class_list]\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Combine all cosine similarities into a single matrix\u001b[39;00m\n\u001b[1;32m     38\u001b[0m cos_sim_matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(similarities_per_class)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'American-Three-toed Woodpecker'"
     ]
    }
   ],
   "source": [
    "## This file will:\n",
    "# 1. Load the JSON file containing the cosine similarities between classes and descriptors\n",
    "# 2. Visualize the cosine similarities using heatmaps (one each for each key in \"data\", and one for the difference between each)\n",
    "#   - There is no limit to the number of keys in \"data\"\n",
    "#   - Use seaborn, with class names on the x-axis and descriptor names on the y-axis\n",
    "#   - The heatmaps should be colored according to the cosine similarity values\n",
    "#   - The class names should be rotated 90 degrees\n",
    "# 3. Save the heatmap as a PNG file\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import os\n",
    "\n",
    "# Load the JSON file\n",
    "def load_json(json_file_path):\n",
    "    with open(json_file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "# Function to dynamically create the descriptor file path\n",
    "def get_descriptor_file_path(dataset_name):\n",
    "    descriptor_file_path = f\"./descriptors/descriptors_{dataset_name}.json\"\n",
    "    return descriptor_file_path\n",
    "\n",
    "# Function to generate a single heatmap for all class-descriptor similarities using Plotly\n",
    "def generate_combined_heatmap(data, dataset_name, output_dir, descriptor_dict):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Extract class names and descriptors\n",
    "    class_list = compute_class_list(descriptor_dict, sort_config=True)\n",
    "    descriptor_list = compute_descriptor_list(descriptor_dict, sort_config=True)\n",
    "\n",
    "    # Extract cosine similarity values for each class\n",
    "    similarities_per_class = [data[dataset_name][class_name][\"cos_sim\"] for class_name in class_list]\n",
    "\n",
    "    # Combine all cosine similarities into a single matrix\n",
    "    cos_sim_matrix = np.array(similarities_per_class)\n",
    "\n",
    "    # Create the heatmap using Plotly\n",
    "    fig = px.imshow(\n",
    "        cos_sim_matrix,\n",
    "        labels=dict(x=\"Descriptors\", y=\"Classes\", color=\"Cosine Similarity\"),\n",
    "        x=descriptor_list,\n",
    "        y=class_list,\n",
    "        color_continuous_scale='RdBu_r',\n",
    "        aspect='auto'\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"Cosine Similarity Heatmap for {dataset_name}\",\n",
    "        xaxis_nticks=len(descriptor_list),\n",
    "        yaxis_nticks=len(class_list)\n",
    "    )\n",
    "\n",
    "    # Save the heatmap as an interactive HTML file\n",
    "    fig.write_html(os.path.join(output_dir, f\"{dataset_name}_combined_heatmap.html\"))\n",
    "\n",
    "    # Optionally, display the figure\n",
    "    fig.show()\n",
    "\n",
    "# Main code execution\n",
    "output_dir = 'combined_heatmaps'  # Output directory for heatmaps\n",
    "\n",
    "# Load the data from the JSON file\n",
    "data = load_json(json_file_path)\n",
    "\n",
    "# Iterate through each dataset in the JSON and generate combined heatmaps\n",
    "for dataset_name in data.keys():\n",
    "    # Dynamically generate the descriptor file path\n",
    "    descriptor_file_path = get_descriptor_file_path(dataset_name)\n",
    "    \n",
    "    # Load the descriptor file for the current dataset\n",
    "    descriptor_dict = load_json(descriptor_file_path)\n",
    "    \n",
    "    # Generate and save the combined heatmap\n",
    "    generate_combined_heatmap(data, dataset_name, output_dir, descriptor_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
